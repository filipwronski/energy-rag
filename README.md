# Energy RAG - System Wyszukiwania Protoko≈Ç√≥w

Zaawansowany system RAG (Retrieval Augmented Generation) do semantycznego wyszukiwania w protoko≈Çach zarzƒÖdu MSM Energetyka z wykorzystaniem:
- üöÄ **OpenRouter API** - embeddings `text-embedding-3-small` (1536-dim)
- üîÑ **Query Expansion** - hybrydowe generowanie wariant√≥w zapyta≈Ñ (LLM + regu≈Çy)
- üéØ **Reciprocal Rank Fusion** - inteligentna agregacja wynik√≥w
- üíæ **SQLite Cache** - redukcja koszt√≥w API o 80-90%
- üìÑ **OCR** - konwersja PDF na Markdown z EasyOCR

## Kluczowe Funkcje

### RAG System
- ‚úÖ **5 wariant√≥w zapytania** - orygina≈Ç + 2 LLM + 2 regu≈Çy (synonimy, kolejno≈õƒá s≈Ç√≥w)
- ‚úÖ **RRF Aggregation** - fuzja 200 wynik√≥w (5 wariant√≥w √ó 10) ‚Üí top 20 najlepszych
- ‚úÖ **Embedding Cache** - SQLite z automatycznym tracking hit rate
- ‚úÖ **Precyzyjne chunki** - 512 znak√≥w z 50 overlap (optymalizacja jako≈õci)
- ‚úÖ **Cost tracking** - pe≈Çna kontrola koszt√≥w API

### Q&A System üÜï
- ‚úÖ **Odpowiedzi w jƒôzyku naturalnym** - DeepSeek V3.2 generuje odpowiedzi na podstawie RAG
- ‚úÖ **Inteligentne filtrowanie** - tylko dokumenty wysokiej jako≈õci (RRF score > 0.04)
- ‚úÖ **Do 20 dokument√≥w kontekstowych** - adaptacyjna liczba wynik√≥w (zwykle 5-15)
- ‚úÖ **Cytowanie ≈∫r√≥de≈Ç** - automatyczne podawanie numer√≥w protoko≈Ç√≥w i dat
- ‚úÖ **Tryb interaktywny** - konwersacyjny interfejs do zadawania pyta≈Ñ
- ‚úÖ **Niski koszt** - DeepSeek V3.2: $0.27/$1.10 per 1M tokens (75x taniej ni≈º Claude)

### PDF OCR
- ‚úÖ Konwersja PDF ‚Üí Markdown z EasyOCR
- ‚úÖ OCR dla polskiego i angielskiego
- ‚úÖ Automatyczna detekcja: tekst PDF vs obrazy
- ‚úÖ Wysokiej jako≈õci rozpoznawanie tekstu

## Instalacja

### 1. Zainstaluj zale≈ºno≈õci

```bash
pip install -r requirements.txt
```

### 2. Skonfiguruj klucz API

Skopiuj szablon konfiguracji i dodaj sw√≥j klucz API:

```bash
# Skopiuj szablon
cp .env.example .env

# Edytuj .env i dodaj sw√≥j klucz OpenRouter API
nano .env
```

Tw√≥j plik `.env` powinien wyglƒÖdaƒá tak:
```
OPEN_ROUTER_API_KEY=sk-or-v1-your_actual_key_here
```

**Jak uzyskaƒá klucz API:**
1. Zarejestruj siƒô na [OpenRouter](https://openrouter.ai/)
2. Przejd≈∫ do [Keys](https://openrouter.ai/keys)
3. Utw√≥rz nowy klucz API
4. Skopiuj klucz do pliku `.env`

**‚ö†Ô∏è BEZPIECZE≈ÉSTWO:**
- **NIGDY** nie commituj pliku `.env` do git (ju≈º jest w `.gitignore`)
- Je≈õli klucz wycieknie, natychmiast go zrotuj na https://openrouter.ai/keys
- Nie udostƒôpniaj klucza publicznie

### 3. Pobierz lub wygeneruj pliki wej≈õciowe

#### Opcja A: Pobierz PDFy (je≈õli dostƒôpne)

```bash
python scripts/download_pdfs.py
```

#### Opcja B: Dodaj w≈Çasne PDFy

Umie≈õƒá pliki PDF w katalogach:
- `input/` - g≈Ç√≥wne protoko≈Çy
- `input-sp/` - protoko≈Çy osiedlowe (opcjonalnie)

**Uwaga:** Katalogi `input/`, `input-sp/`, `output/` i `output-sp/` sƒÖ ignorowane przez git. Musisz wygenerowaƒá je lokalnie.

### 4. Zbuduj cache i indeks Qdrant

```bash
# Uruchom Qdrant (Docker)
docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant

# W nowym terminalu: konwertuj PDFy na Markdown (je≈õli masz PDFy)
python pdf_to_markdown_easyocr.py

# Zbuduj indeks Qdrant
python scripts/build_index.py
```

**Wymagania:**
- Python 3.8+
- Docker (dla Qdrant)
- OpenRouter API key ([uzyskaj tutaj](https://openrouter.ai/))
- ~2GB wolnego miejsca

---

## PDF to Markdown (OCR)

### Konwersja PDF na Markdown

System u≈ºywa EasyOCR do rozpoznawania tekstu z zeskanowanych PDF.

```bash
# Pobierz PDFy (opcjonalnie)
python scripts/download_pdfs.py

# Konwertuj PDF ‚Üí Markdown
python pdf_to_markdown_easyocr.py
```

**Proces:**
1. PyMuPDF wyciƒÖga strony jako obrazy
2. EasyOCR rozpoznaje tekst (polski + angielski)
3. Formatowanie jako Markdown z nag≈Ç√≥wkami stron
4. Zapisz do `output/`

**Przyk≈Çad wyniku:**
```markdown
# Protok√≥≈Ç nr 1 z ustale≈Ñ ZarzƒÖdu w dniach  02.-14.01.2025 r

*Dokument zawiera 3 stron*
*Tekst rozpoznany automatycznie przez OCR*

---

## Strona 1

Protok√≥≈Ç nr 1
ustale≈Ñ ZarzƒÖdu MSM "Energetyka"
w dniach 02.-14.01.2025 r.
...
```

**Dok≈Çadno≈õƒá OCR:**
- ‚úÖ Czysty druk: 95-99%
- ‚úÖ Skanowane dokumenty: 90-95%
- ‚ö†Ô∏è Pisane rƒôcznie: 60-80%

**RozwiƒÖzywanie problem√≥w OCR:**
- Sprawd≈∫ jako≈õƒá skan√≥w (min 150 DPI)
- Jasne obrazy z dobrym kontrastem
- Pierwsze uruchomienie pobiera modele (~100-200MB)

## Struktura projektu

```
energy-rag/
‚îú‚îÄ‚îÄ input/                          # Pliki PDF do konwersji
‚îú‚îÄ‚îÄ output/                         # Wygenerowane pliki Markdown
‚îú‚îÄ‚îÄ rag/                           # Modu≈Ç RAG (Enhanced)
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Konfiguracja (embeddings, RRF, cache)
‚îÇ   ‚îú‚îÄ‚îÄ openrouter_client.py       # OpenRouter API client z retry logic
‚îÇ   ‚îú‚îÄ‚îÄ cache.py                   # SQLite cache dla embeddings
‚îÇ   ‚îú‚îÄ‚îÄ openrouter_embedder.py     # Embedder z cache integration
‚îÇ   ‚îú‚îÄ‚îÄ query_expander.py          # Hybrydowa ekspansja zapyta≈Ñ
‚îÇ   ‚îú‚îÄ‚îÄ rrf_aggregator.py          # Reciprocal Rank Fusion
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_retriever.py      # G≈Ç√≥wny orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ qa_system.py               # System Q&A z LLM
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py                 # Parsowanie i dzielenie dokument√≥w
‚îÇ   ‚îî‚îÄ‚îÄ retriever.py               # Legacy retriever (backward compatibility)
‚îú‚îÄ‚îÄ scripts/                       # Skrypty u≈ºytkowe
‚îÇ   ‚îú‚îÄ‚îÄ build_index.py             # Indeksowanie z cost estimation
‚îÇ   ‚îú‚îÄ‚îÄ search.py                  # Enhanced CLI (--verbose, --stats)
‚îÇ   ‚îú‚îÄ‚îÄ ask.py                     # Q&A system - odpowiedzi w jƒôzyku naturalnym
‚îÇ   ‚îî‚îÄ‚îÄ download_pdfs.py           # Pobieranie PDF
‚îú‚îÄ‚îÄ tests/                         # Testy
‚îÇ   ‚îî‚îÄ‚îÄ test_retrieval.py          # Test suite dla RAG
‚îú‚îÄ‚îÄ .env                           # API keys (OPEN_ROUTER_API_KEY)
‚îú‚îÄ‚îÄ embedding_cache.db             # SQLite cache (auto-generated)
‚îú‚îÄ‚îÄ requirements.txt               # Zale≈ºno≈õci Python
‚îî‚îÄ‚îÄ README.md                      # Dokumentacja
```

---

## Wymagania Systemowe

### Minimalne
- Python 3.8+
- Docker (dla Qdrant)
- 4GB RAM
- 2GB wolnego miejsca

### Zalecane
- Python 3.10+
- 8GB RAM (dla OCR + RAG)
- SSD dla szybszego cache access

### Zale≈ºno≈õci Python
```
# Core
qdrant-client>=1.7.0
requests>=2.31.0
python-dotenv>=1.0.0

# OCR (opcjonalne - tylko dla konwersji PDF)
pymupdf>=1.23.0
easyocr>=1.7.0
Pillow>=10.0.0
numpy>=1.24.0
```

---

## FAQ

### Czy mogƒô u≈ºyƒá innego modelu embeddings?

Tak! Zmie≈Ñ w [rag/config.py](rag/config.py:8):
```python
EMBEDDING_MODEL = "openai/text-embedding-3-large"  # Wiƒôkszy model
EMBEDDING_DIM = 3072
```

**Uwaga:** Wymaga przeindeksowania bazy.

### Czy mogƒô wr√≥ciƒá do lokalnego modelu (bez API)?

Tak, zachowali≈õmy backward compatibility. Zakomentuj nowe modu≈Çy i u≈ºyj starego `PolishEmbedder`:

```python
# In scripts/search.py
from rag.retriever import ProtocolRetriever  # Old retriever
```

### Jak czƒôsto powinienem czy≈õciƒá cache?

Nigdy, chyba ≈ºe:
- Cache > 100MB (sprawd≈∫: `ls -lh embedding_cache.db`)
- Zmieniasz model embeddings
- Testujesz cache hit rate od zera

### Czy mogƒô u≈ºyƒá innego LLM do query expansion?

Tak! W [rag/query_expander.py](rag/query_expander.py:expand_hybrid):
```python
# Zmie≈Ñ model
payload = {
    "model": "anthropic/claude-3.5-sonnet",  # Zamiast gpt-4o-mini
    ...
}
```

### Czy mogƒô u≈ºyƒá innego modelu LLM do Q&A?

Tak! System Q&A domy≈õlnie u≈ºywa DeepSeek V3.2 (tani i dobry), ale mo≈ºesz zmieniƒá na inny:

**Opcja 1:** Zmie≈Ñ domy≈õlny model w [rag/qa_system.py](rag/qa_system.py:13):
```python
def __init__(self, model: str = "anthropic/claude-3.5-sonnet"):  # Zamiast deepseek/deepseek-chat
```

**Opcja 2:** Podaj model podczas inicjalizacji:
```python
from rag.qa_system import ProtocolQASystem
qa = ProtocolQASystem(model="anthropic/claude-3.5-sonnet")
```

**Dostƒôpne modele na OpenRouter:**
- `deepseek/deepseek-chat` - DeepSeek V3.2 (najta≈Ñszy, dobry) ‚úÖ
- `google/gemini-2.0-flash-exp:free` - Gemini 2.0 Flash (darmowy!)
- `anthropic/claude-3.5-sonnet` - Claude 3.5 Sonnet (najlepszy, drogi)
- `openai/gpt-4o` - GPT-4o (bardzo dobry, drogi)
- Pe≈Çna lista: https://openrouter.ai/models

### Jak dostosowaƒá pr√≥g jako≈õci wynik√≥w?

System filtruje s≈Çabe wyniki u≈ºywajƒÖc `MIN_RRF_SCORE` (domy≈õlnie 0.04). Mo≈ºesz to zmieniƒá w [rag/config.py](rag/config.py:32):

```python
MIN_RRF_SCORE = 0.04  # Domy≈õlny pr√≥g
```

**Wskaz√≥wki:**
- **0.02** - wiƒôcej wynik√≥w, mo≈ºe zawieraƒá s≈Çabe dopasowania
- **0.04** - zbilansowany (zalecany) ‚úÖ
- **0.06** - tylko bardzo dobre dopasowania, mniej wynik√≥w
- **0.10** - ekstremalnie restrykcyjny, tylko idealne dopasowania

**Typowe warto≈õci RRF score:**
- 0.08+ - doskona≈Çe dopasowanie (top 3 wyniki)
- 0.04-0.08 - dobre dopasowanie (wyniki 4-10)
- 0.02-0.04 - s≈Çabe dopasowanie (czƒôsto nieistotne)
- <0.02 - bardzo s≈Çabe (szum)

### Czy dzia≈Ça offline?

Nie w obecnej wersji (wymaga OpenRouter API). Dla offline:
1. Przywr√≥ƒá `PolishEmbedder` (lokalny model)
2. Wy≈ÇƒÖcz LLM expansion (tylko rule-based)
3. Przeindeksuj z lokalnym modelem

---

## Roadmap

### Planowane Funkcje

- [ ] **Semantic Reranking** - 2-stage retrieval z cross-encoder
- [ ] **Query Classification** - filtrowanie po typie protoko≈Çu
- [ ] **Highlight Variants** - pokazywanie kt√≥re s≈Çowa z wariant√≥w pasujƒÖ
- [ ] **A/B Testing** - por√≥wnanie z poprzednim systemem
- [ ] **Streaming Results** - progressive display dla d≈Çugich wynik√≥w
- [ ] **Multi-language Support** - rozszerzenie na inne jƒôzyki
- [ ] **Web UI** - interfejs graficzny (Streamlit/Gradio)

### Mo≈ºliwe Optymalizacje

- [ ] **Hybrid Search** - po≈ÇƒÖczenie vector + keyword (BM25)
- [ ] **Result Caching** - cache ca≈Çych wynik√≥w (nie tylko embeddings)
- [ ] **Batch Querying** - obs≈Çuga wielu zapyta≈Ñ jednocze≈õnie
- [ ] **Custom Synonyms** - learning from query logs
- [ ] **Feedback Loop** - implicit relevance feedback

---

## Contributing

Zg≈Çaszaj bugi i propozycje funkcji przez [GitHub Issues](https://github.com/fwronski/energy-rag/issues).

Pull requesty mile widziane! üéâ

---

## Licencja

Open source - wykorzystuj dowolnie!

---

## Acknowledgments

Technologie u≈ºyte w projekcie:
- **OpenRouter** - unified LLM & embeddings API
- **Qdrant** - vector database
- **EasyOCR** - optical character recognition
- **PyMuPDF** - PDF processing
- **Anthropic Claude** - code generation & planning

---

**Built with ‚ù§Ô∏è for better document search**

# Wyszukiwarka RAG - Szybki Start

## 1. Uruchom Qdrant (Docker)

```bash
docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant
```

## 2. Przeindeksuj dokumenty

```bash
python scripts/build_index.py
```

**Co siƒô dzieje:**
- Przetwarzanie ~458 plik√≥w markdown z `output/`
- Chunking: 512 znak√≥w z 50 overlap ‚Üí ~4,500-5,000 chunk√≥w
- Embeddings przez OpenRouter API (`text-embedding-3-small`)
- Oszacowanie koszt√≥w i potwierdzenie przed rozpoczƒôciem
- **Koszt jednorazowy: ~$0.01-0.02**
- Czas: ~5-10 minut

**Przyk≈Çadowy output:**
```
======================================================================
Building Qdrant index for protocol documents
======================================================================

1. Initializing Qdrant client and embedder...
   ‚úì OpenRouter embedder initialized (cache: enabled)

2. Creating collection 'energy_protocols'...
   ‚úì Created collection with 1536-dim vectors, cosine distance

3. Processing documents...
   ‚úì Processed 458 files

4. Estimating indexing cost...
   Chunks to embed: 4,832
   Estimated tokens: 483,200
   Estimated cost: $0.0097

   Proceed with indexing? (yes/no): yes

5. Generating embeddings and indexing 4,832 chunks...
   Processing chunks 1-50/4832...
   Processing chunks 51-100/4832...
   ...

‚úì Indexing complete!
‚úì Time elapsed: 287.3s (0.06s per chunk)
‚úì Actual cost: ~$0.0097
```

## 3a. Zadawaj pytania (Q&A System) üÜï

### Tryb podstawowy

```bash
python scripts/ask.py "jakie remonty by≈Çy przeprowadzane przy ul. Bonifacego 66?"
```

**Output:**
```
======================================================================
Q&A System - Protoko≈Çy ZarzƒÖdu MSM Energetyka
Powered by RAG + DeepSeek V3.2
======================================================================

Pytanie: jakie remonty by≈Çy przeprowadzane przy ul. Bonifacego 66?

======================================================================
ODPOWIED≈π:
======================================================================
Na podstawie przeszukanych dokument√≥w, w budynku przy ul. Bonifacego 66
przeprowadzono nastƒôpujƒÖce remonty:

1. **Remont instalacji c.o.** (Protok√≥≈Ç nr 15, 2024)
   - Wymiana grzejnik√≥w w lokalach
   - Koszt: 45 000 z≈Ç

2. **Remont dachu** (Protok√≥≈Ç nr 23, 2023)
   - Naprawa pokrycia dachowego
   - Wymiana rynien
   - Koszt: 78 000 z≈Ç

3. **Remont klatki schodowej** (Protok√≥≈Ç nr 8, 2023)
   - Malowanie ≈õcian
   - Wymiana lamp
   - Koszt: 12 000 z≈Ç

üìö ≈πr√≥d≈Ça (20 dokument√≥w):
  1. Protok√≥≈Ç nr 15, Strona 2 (Data: 19.08.-03.09.2024)
  2. Protok√≥≈Ç nr 23, Strona 1 (Data: 21.-28.06.2023)
  ...
======================================================================
```

### Tryb interaktywny

```bash
python scripts/ask.py
```

Pozwala zadawaƒá wiele pyta≈Ñ w jednej sesji:
```
üí¨ Pytanie: jakie decyzje podjƒôto w sprawie wiat ≈õmietnikowych?
üí¨ Pytanie: kto zosta≈Ç zatrudniony w 2023 roku?
üí¨ Pytanie: exit
```

### Komendy specjalne

- `--verbose` - tryb szczeg√≥≈Çowy (poka≈º statystyki RAG)
- `--sources` - w≈ÇƒÖcz/wy≈ÇƒÖcz wy≈õwietlanie ≈∫r√≥de≈Ç
- `--stats` - statystyki systemu
- `--no-sources` - uruchom bez wy≈õwietlania ≈∫r√≥de≈Ç

**Przyk≈Çady:**
```bash
# Pytanie z trybem szczeg√≥≈Çowym
python scripts/ask.py --verbose "sprawy pracownicze"

# Pytanie bez wy≈õwietlania ≈∫r√≥de≈Ç
python scripts/ask.py --no-sources "wiaty ≈õmietnikowe"
```

---

## 3b. Wyszukuj fragmenty (klasyczny RAG)

### Tryb podstawowy

```bash
python scripts/search.py "sprawy pracownicze"
```

### Tryb szczeg√≥≈Çowy (--verbose)

```bash
python scripts/search.py --verbose "sprawy pracownicze"
```

**Pokazuje:**
- Wygenerowane warianty zapytania (5 wersji)
- Statystyki RRF fusion
- Cache hit rate
- Liczba wywo≈Ça≈Ñ API

### Tryb interaktywny

```bash
python scripts/search.py
```

**Dostƒôpne komendy:**
- `--verbose` - w≈ÇƒÖcz/wy≈ÇƒÖcz tryb szczeg√≥≈Çowy
- `--stats` - poka≈º statystyki sesji (cache, API calls)
- `exit` / `quit` - zako≈Ñcz

## Przyk≈Çad wyniku wyszukiwania

### Podstawowy output

```
======================================================================
RAG Search - Protoko≈Çy ZarzƒÖdu MSM Energetyka
Enhanced with Query Expansion + RRF
======================================================================

Wyniki wyszukiwania dla: "sprawy pracownicze"
Znaleziono 5 wynik√≥w

======================================================================
1. [Protok√≥≈Ç nr 3, Strona 1] (RRF: 0.0421)
≈πr√≥d≈Ço: Protok√≥≈Ç nr 3 z ustale≈Ñ ZarzƒÖdu w dniach  29.01. - 11.02.2025 r
Data: 29.01. - 11.02.2025
Znalezione przez 4 wariant√≥w zapytania

Ad 3 ZarzƒÖd na wniosek: Zespo≈Çu Nadzoru Eksploatacyjnego Koordynacji
Remont√≥w zaakceptowa≈Ç sk≈Çad Komisji Przetargowej w przetargu nr 4/2025...
======================================================================
```

### Verbose mode (--verbose)

```
üîç Processing query: "sprawy pracownicze"
   Generating 5 query variants...
   Query variants:
      1. [original] sprawy pracownicze
      2. [llm] zagadnienia dotyczƒÖce zatrudnienia
      3. [llm] kwestie kadrowe
      4. [synonym] kwestia pracownik
      5. [word_order] pracownicze sprawy

   Searching Qdrant (10 results per variant)...
      Variant 1: 10 results
      Variant 2: 10 results
      Variant 3: 10 results
      Variant 4: 10 results
      Variant 5: 10 results

   Applying Reciprocal Rank Fusion...
      ‚úì Fused to 5 final results
      Avg variants per result: 3.2

----------------------------------------------------------------------
Szczeg√≥≈Çy wyszukiwania:
  Warianty zapyta≈Ñ: 5
    1. [original] sprawy pracownicze
    2. [llm] zagadnienia dotyczƒÖce zatrudnienia
    3. [llm] kwestie kadrowe
    4. [synonym] kwestia pracownik
    5. [word_order] pracownicze sprawy

  Statystyki fuzji (RRF):
    ≈örednia wariant√≥w na wynik: 3.2

  Cache:
    Trafienia: 12
    Chybienia: 3
    Wsp√≥≈Çczynnik trafie≈Ñ: 80.0%
    Wywo≈Çania API: 3
----------------------------------------------------------------------
```

---

## Jak Dzia≈Ça Enhanced RAG?

### Architektura Systemu

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USER QUERY                               ‚îÇ
‚îÇ                  "sprawy pracownicze"                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   QUERY EXPANSION                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  Original    ‚îÇ  ‚îÇ LLM (GPT-4o) ‚îÇ  ‚îÇ Rule-Based   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  Query       ‚îÇ  ‚îÇ 2 variants   ‚îÇ  ‚îÇ 2 variants   ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Output: 5 query variants                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EMBEDDING (with Cache)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ For each variant:                                     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  1. Check SQLite cache (SHA256 hash)                 ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  2. If miss ‚Üí OpenRouter API (text-embedding-3-small)‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  3. Store in cache for future reuse                  ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Output: 5 √ó 1536-dim vectors                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  VECTOR SEARCH (Qdrant)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ For each variant vector:                              ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query Qdrant collection (cosine similarity)        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Retrieve top 10 chunks                             ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Total: 5 variants √ó 10 = 50 candidate chunks       ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              RECIPROCAL RANK FUSION (RRF)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Formula: RRF_score(d) = Œ£ 1/(k + rank(d))            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ where k=60 (constant), rank = position (1-indexed)    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ Process:                                               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  1. Deduplicate chunks across variants                ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  2. Calculate RRF score for each unique chunk         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  3. Sort by RRF score (descending)                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  4. Return top 5 final results                        ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FINAL RESULTS                              ‚îÇ
‚îÇ  ‚Ä¢ Top 5 chunks with highest RRF scores                         ‚îÇ
‚îÇ  ‚Ä¢ Metadata: source, page, protocol number, contributing vars   ‚îÇ
‚îÇ  ‚Ä¢ Display with statistics (cache, API calls, fusion)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Proces Krok po Kroku

#### 1. Query Expansion (5 wariant√≥w)

**Cel:** Zwiƒôkszyƒá recall przez r√≥≈ºne sformu≈Çowania tego samego pytania.

| Metoda | Przyk≈Çad | Generator |
|--------|----------|-----------|
| **Original** | "sprawy pracownicze" | Oryginalne zapytanie |
| **LLM #1** | "zagadnienia dotyczƒÖce zatrudnienia" | GPT-4o-mini |
| **LLM #2** | "kwestie kadrowe" | GPT-4o-mini |
| **Synonym** | "kwestia pracownik" | S≈Çownik synonim√≥w |
| **Word order** | "pracownicze sprawy" | Permutacja s≈Ç√≥w |

**Fallback:** Je≈õli LLM zawiedzie ‚Üí rule-based only + padding z orygina≈Çem.

#### 2. Embedding z Cache

```python
# Dla ka≈ºdego wariantu:
query_hash = sha256(variant_text)

if cache.exists(query_hash):
    embedding = cache.get(query_hash)  # Cache HIT
else:
    embedding = openrouter.get_embedding(variant_text)  # API call
    cache.put(query_hash, embedding)   # Zapisz w cache

# Result: 5 √ó 1536-dimensional vectors
```

**Cache Benefits:**
- 80-90% reduction w API calls (po ~50 zapytaniach)
- Instant retrieval dla powt√≥rzonych queries
- SQLite - lightweight, zero setup

#### 3. Vector Search (Qdrant)

```python
for variant_embedding in variant_embeddings:
    results = qdrant.search(
        collection="energy_protocols",
        query_vector=variant_embedding,
        limit=10  # Top 10 per variant
    )
    all_results.append(results)

# Total candidates: 5 variants √ó 10 results = 50 chunks
```

#### 4. Reciprocal Rank Fusion

**Formula:**
```
RRF_score(chunk) = Œ£ (dla wszystkich wariant√≥w gdzie chunk siƒô pojawi≈Ç)
                    1 / (60 + rank)

gdzie:
- rank = pozycja chunka w wynikach tego wariantu (1-indexed)
- 60 = sta≈Ça RRF z literatury (balans precision/recall)
```

**Przyk≈Çad:**
```
Chunk A pojawi≈Ç siƒô w:
- Variant 1: rank 2  ‚Üí 1/(60+2) = 0.0161
- Variant 3: rank 5  ‚Üí 1/(60+5) = 0.0154
- Variant 4: rank 1  ‚Üí 1/(60+1) = 0.0164
Total RRF score = 0.0479

Chunk B pojawi≈Ç siƒô w:
- Variant 2: rank 1  ‚Üí 1/(60+1) = 0.0164
Total RRF score = 0.0164

Ranking: Chunk A > Chunk B (wiƒôcej wariant√≥w = wy≈ºszy score)
```

**Zalety RRF:**
- Chunks pojawiajƒÖce siƒô w wielu wariantach = boost
- Nie wymaga kalibracji score thresholds
- Robust przeciw outlierom

#### 5. Rezultat

Top 5 chunks z:
- **RRF score** - g≈Ç√≥wny ranking metric
- **Contributing variants** - kt√≥re warianty znalaz≈Çy ten chunk
- **Source metadata** - protok√≥≈Ç, strona, data
- **Cache stats** - hit rate, API calls

---

## Konfiguracja

Parametry w [rag/config.py](rag/config.py):

### Embeddings
```python
EMBEDDING_MODEL = "openai/text-embedding-3-small"
EMBEDDING_DIM = 1536
```

### Chunking
```python
MAX_CHUNK_SIZE = 512    # Zmniejszone z 1000 dla lepszej precyzji
CHUNK_OVERLAP = 50      # Zmniejszone z 100
```

### Query Expansion
```python
NUM_QUERY_VARIANTS = 5
NUM_LLM_VARIANTS = 2
NUM_RULE_VARIANTS = 2
```

### RRF
```python
RRF_K = 60                  # Standard constant
RESULTS_PER_VARIANT = 10    # Candidates per variant
DEFAULT_TOP_K = 20          # Maximum final results
MIN_RRF_SCORE = 0.04        # Minimum quality threshold (filters weak matches)
```

**Filtrowanie jako≈õci:**
- System zwraca maksymalnie 20 wynik√≥w, ale tylko te z RRF score > 0.04
- W praktyce zwraca 5-15 wynik√≥w wysokiej jako≈õci
- Eliminuje s≈Çabe dopasowania (score < 0.04) kt√≥re mog≈Çyby wprowadzaƒá szum

### Cache
```python
ENABLE_CACHE = True
CACHE_DB_PATH = "embedding_cache.db"
```

---

## Koszty i Optymalizacje

### Koszty API (OpenRouter)

**Model Embeddings:** `text-embedding-3-small` - $0.00002 per 1K tokens
**Model LLM (Query Expansion):** `gpt-4o-mini` - $0.15/$0.60 per 1M tokens (input/output)
**Model LLM (Q&A):** `deepseek/deepseek-chat` (DeepSeek V3.2) - $0.27/$1.10 per 1M tokens (input/output)

#### Jednorazowe Przeindeksowanie
```
~4,500 chunks √ó 100 tokens/chunk = 450,000 tokens
Cost: (450,000 / 1,000) √ó $0.00002 = $0.009

Faktyczny koszt: $0.01-0.02
```

#### Per Query (klasyczny RAG - search.py)
```
Komponenty:
1. Query expansion (LLM):     ~$0.000025
2. Embeddings (5 variants):    ~$0.000002
Total (bez cache):             ~$0.000027

Z cache (80% hit rate):        ~$0.000025
```

#### Per Query (Q&A System - ask.py)
```
Komponenty:
1. RAG search (j.w.):          ~$0.000025
2. DeepSeek V3.2 answer:       ~$0.000135  (500 tokens in + 500 tokens out)
Total:                         ~$0.000160

Koszt 1000 pyta≈Ñ Q&A: ~$0.16
```

**Por√≥wnanie modeli Q&A:**
- DeepSeek V3.2: $0.000160/query ‚Üí **$0.16 per 1000 queries** ‚úÖ
- Claude 3.5 Sonnet: $0.012/query ‚Üí **$12 per 1000 queries** (75x dro≈ºej!)
- GPT-4o: $0.0075/query ‚Üí **$7.50 per 1000 queries** (47x dro≈ºej!)

#### Miesiƒôcznie
```
Scenariusz A (tylko search.py):
  1,000 zapyta≈Ñ/miesiƒÖc √ó $0.000025 = $0.025
  Roczny koszt: ~$0.30

Scenariusz B (tylko ask.py z DeepSeek):
  1,000 pyta≈Ñ Q&A/miesiƒÖc √ó $0.000160 = $0.16
  Roczny koszt: ~$1.92

Scenariusz C (mieszany):
  500 search + 500 Q&A = (500 √ó $0.000025) + (500 √ó $0.000160) = $0.09
  Roczny koszt: ~$1.11
```

**Wniosek:** System jest ekstremalnie tani w utrzymaniu! üéâ Nawet z DeepSeek Q&A koszt to tylko ~$2/rok dla 1000 pyta≈Ñ miesiƒôcznie!

### Cache Effectiveness

Po ~50 zapytaniach:
```
Cache Hit Rate: 70-90%
API Calls Reduction: 80-90%
Cost Savings: ~$0.80 per 1,000 queries
```

**Cache Storage:**
```
~100 queries = ~1MB w SQLite
~1,000 queries = ~10MB
```

### Performance Metrics

| Metryka | Cold Cache | Warm Cache |
|---------|------------|------------|
| **Query Time** | 1.2-1.5s | 0.8-1.0s |
| **API Calls** | 5-6 | 1-2 |
| **Cost** | $0.00003 | $0.000025 |

**Bottlenecks:**
- LLM query expansion: ~500-700ms (nie cacheable)
- Embeddings: ~50ms per variant (cacheable)
- Qdrant search: ~50ms per variant
- RRF fusion: ~10ms

---

## Testy

### Uruchom Test Suite

```bash
python tests/test_retrieval.py
```

**Testy:**
1. ‚úÖ Query expansion - generowanie wariant√≥w
2. ‚úÖ RRF fusion - agregacja z mock data
3. ‚úÖ End-to-end search - pe≈Çny flow (wymaga Qdrant)
4. ‚úÖ Cache hit rate - efektywno≈õƒá cache

### Przyk≈Çadowy Output
```
======================================================================
Running Enhanced RAG System Tests
======================================================================

======================================================================
Test 1: Query Expansion
======================================================================

Original: sprawy pracownicze
  1. [original] sprawy pracownicze
  2. [llm] zagadnienia dotyczƒÖce zatrudnienia
  3. [llm] kwestie kadrowe
  4. [synonym] kwestia pracownik
  5. [word_order] pracownicze sprawy

‚úì Query expansion test passed

======================================================================
Test 2: RRF Fusion
======================================================================

Fused results:
  1. doc2.md (RRF: 0.0325, variants: 2)
  2. doc1.md (RRF: 0.0325, variants: 2)
  3. doc3.md (RRF: 0.0246, variants: 2)

‚úì RRF fusion test passed

======================================================================
‚úì All tests passed!
======================================================================
```

---

## Monitoring i Debugging

### Cache Statistics

W trybie interaktywnym:
```bash
python scripts/search.py
Zapytanie: --stats
```

Output:
```
Statystyki:
  Przetworzone zapytania: 23
  Wygenerowane warianty: 115
  Cache - trafienia: 87
  Cache - chybienia: 28
  Cache - wsp√≥≈Çczynnik: 75.7%
```

### Verbose Mode

Debuguj ka≈ºdy krok:
```bash
python scripts/search.py --verbose "test query"
```

Pokazuje:
- Wygenerowane warianty (z metodami)
- Wyniki per variant
- RRF scores i contributing variants
- Cache hit/miss dla ka≈ºdego embedding

### Cache Management

**Sprawd≈∫ rozmiar:**
```bash
ls -lh embedding_cache.db
```

**Wyczy≈õƒá cache:**
```python
from rag.cache import EmbeddingCache
cache = EmbeddingCache()
cache.clear()
```

**Statystyki cache:**
```python
stats = cache.get_stats()
print(f"Entries: {stats['total_entries']}")
print(f"Size: {stats['db_size_mb']} MB")
```

---

## Troubleshooting

### Problem: Rate Limiting (429 errors)

**Symptom:** `Rate limited. Waiting 5s...`

**RozwiƒÖzanie:**
1. Zwiƒôksz `time.sleep(0.5)` ‚Üí `time.sleep(1.0)` w [openrouter_client.py](rag/openrouter_client.py:96)
2. Zmniejsz `batch_size` w [build_index.py](scripts/build_index.py:68) z 50 ‚Üí 20

### Problem: Cache ro≈õnie zbyt szybko

**Symptom:** `embedding_cache.db > 100MB`

**RozwiƒÖzanie:**
```python
from rag.cache import EmbeddingCache
cache = EmbeddingCache()
cache.clear()  # Usu≈Ñ wszystkie wpisy
```

### Problem: LLM expansion failures

**Symptom:** `Warning: LLM expansion failed`

**RozwiƒÖzanie:**
- Sprawd≈∫ `OPEN_ROUTER_API_KEY` w `.env`
- Sprawd≈∫ limity API na [OpenRouter Dashboard](https://openrouter.ai/activity)
- System automatycznie fallback na rule-based expansion

### Problem: Wolne queries (>3s)

**Symptom:** Consistent query time > 2s

**RozwiƒÖzanie:**
1. Zmniejsz `RESULTS_PER_VARIANT` w [config.py](rag/config.py:27) z 10 ‚Üí 5
2. Zmniejsz `NUM_LLM_VARIANTS` z 2 ‚Üí 1
3. Poczekaj na wzrost cache hit rate (po ~50 queries)

### Problem: Za du≈ºo s≈Çabych wynik√≥w

**Symptom:** Wyniki z niskim RRF score (0.01-0.03), nieistotne dokumenty

**RozwiƒÖzanie:**
Zwiƒôksz `MIN_RRF_SCORE` w [config.py](rag/config.py:32):
```python
MIN_RRF_SCORE = 0.06  # Zamiast 0.04 (bardziej restrykcyjny)
```

### Problem: Za ma≈Ço wynik√≥w

**Symptom:** System zwraca tylko 2-3 wyniki, chocia≈º istniejƒÖ inne istotne dokumenty

**RozwiƒÖzanie:**
1. Zmniejsz `MIN_RRF_SCORE` w [config.py](rag/config.py:32):
   ```python
   MIN_RRF_SCORE = 0.02  # Zamiast 0.04 (mniej restrykcyjny)
   ```
2. Zwiƒôksz `RESULTS_PER_VARIANT`: 10 ‚Üí 15 (wiƒôcej candidat√≥w)
3. Dostosuj `RRF_K`: 60 ‚Üí 40 (wiƒôksza diversity)

### Problem: Wyniki bardzo podobne lub powtarzajƒÖce siƒô

**Symptom:** Top 5 results z tego samego dokumentu, brak r√≥≈ºnorodno≈õci

**RozwiƒÖzanie:**
1. Dostosuj `RRF_K` in [config.py](rag/config.py:26): 60 ‚Üí 40 (wiƒôksza diversity)
2. Rozszerz s≈Çownik synonim√≥w w [query_expander.py](rag/query_expander.py:14-27)

---

## Rebuild Indeksu

Je≈õli dodasz nowe pliki markdown do `output/`:

```bash
python scripts/build_index.py
```

**UWAGA:** To usunie obecny indeks i utworzy nowy. Cache pozostanie nienaruszony.

---

## Licencja

Open source - wykorzystuj dowolnie!
